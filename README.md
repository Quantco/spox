# Spox

[![CI](https://github.com/Quantco/spox/actions/workflows/ci.yml/badge.svg)](https://github.com/Quantco/spox/actions/workflows/ci.yml)
[![Documentation](https://img.shields.io/badge/docs-latest-success?style=plastic)](https://docs.dev.quantco.cloud/qc-github-artifacts/Quantco/spox/latest/index.html)

Spox is a library for constructing computational graphs following the [ONNX standard](https://github.com/onnx/onnx/).

Spox:

- Follows the ONNX standard while also allowing Pythonic code.
- Enforces the strong type system of ONNX, by raising errors as early possible and with Python tracebacks, performing type checking eagerly.
- Supports the entirety of modern opsets, including features like subgraphs (control flow) and types other than tensors (like sequences and optionals).
  - Standard operators all have typed Python signatures and docstrings!
- Is designed for predictability allowing simple composition, so no mutable types are passed around. If it's legal Python, it should be legal ONNX.

## Installation

Spox is published on conda-forge and can be installed as expected:

```bash
conda install spox
```

## Introduction

### Variables (`Var`)

The `Var` – variable – is the most prominent abstraction in Spox.

Like its name suggests, is represents a variable (a _placeholder/lazy_ value) in the computational graph. Usually its type is a `tensor`, but it also covers `optional`, `sequence`, and `map` types. A `Var` is an output of a node (operator) in the graph and can also be visualised as an outgoing edge.

A `Var` object does not have a concrete value, but it does have an explicit type. For instance, it may have type Tensor, which is parametrised by the element type (like `numpy.float32`) and shape (a tuple like `('N', 2)` - meaning _N x 2_).

For example, given `a: Var` and `b: Var`, `c: Var = add(a, b)` is the Var representing the sum of `a` and `b`.
The type and shape information of `c` is automatically derived from the inputs following the ONNX type inference implementation.
The `add` function is an _operator constructor_, which internally constructs an `Add` node and returns a variable representing its output.

`Var`s maintain the information about their ancestry. This implicit graph as constructed can be later built into a full ONNX computational graph. The only needed assumption is that `Var` objects may not be modified.

#### Operator constructors

In ONNX, operators take _inputs_ (`Var`s), which may be optional (`Optional[Var]`) or variadic (`Sequence[Var]`).

Additionally, they may be parameterised by _attributes_, which are passed as keyword arguments. These are type-hinted and are usually standard Python or numpy datatypes (like `int`, `float`, `str`, `numpy.dtype`, ...)

Spox provides constructor functions for all operators defined by the ONNX specification.
This includes the [`ai.onnx`](https://github.com/onnx/onnx/blob/main/docs/Operators.md) as well as the [`ai.onnx.ml`](https://github.com/onnx/onnx/blob/main/docs/Operators-ml.md) domain.

Constructors are autogenerated with the `src/generate.py` script based on the list of operator schemas provided by `onnx`. The modules with them may be imported from `spox.opset.ai.onnx.*`, at a given version of the opset.

### Graphs

To construct a computational graph we need to introduce some variables. This is done by constructing a special _argument_ `Var` (sometimes called a _source_ or _graph input_).

Once such a placeholder is constructed, any operator constructors may be used on it. When the graph is built, only nodes which are necessary to compute the requested results are included.

If a computational graph contains operations from different versions of the standard, Spox will attempt to update all operators to the newest version observed in the graph. This process is known as _adapting_ and is achieved with the public ONNX API, though on a more fine-grained level.

### Running

Once you have constructed an `onnx.ModelProto`, refer to the ONNX documentation on how to process it further. For example, you may save it to a file with `onnx.save` or convert it to bytes via `.SerializeToString()`.s

The resulting ONNX model may be executed using a runtime such as the reference [ONNX Runtime](https://onnxruntime.ai).

### Example usage

This example constructs a graph, taking floating point vectors `a`, `b`, `c`, and returning `r = a*b + c`.

```py
import numpy
import onnxruntime

from spox import Tensor
from spox._graph import arguments, results  # FIXME: Unstable API!
import spox.opset.ai.onnx.v17 as op

# Construct a Tensor type representing a (1D) vector of float32, of size N.
VectorFloat32 = Tensor(numpy.float32, ('N',))

# a, b, c are all vectors and named the same in the graph
a, b, c = arguments(a=VectorFloat32, b=VectorFloat32, c=VectorFloat32)

# p represents the Var equivalent to a * b
p = op.mul(a, b)
q = op.add(p, c)
# q = op.add(op.mul(a, b), c) works exactly the same

# Construct a Spox graph with the result
graph = results(r=q)

# We leave Spox-land and use ONNX Runtime to execute
# - * -
session = onnxruntime.InferenceSession(graph.to_onnx_model().SerializeToString())
(result,) = session.run(None, {
	'a': numpy.array([1, 2, 3], dtype=numpy.float32),
	'b': numpy.array([2, 4, 1], dtype=numpy.float32),
	'c': numpy.array([1, 0, 1], dtype=numpy.float32)
})
# As expected, 3 = 1*2 + 1, etc.
assert (result == numpy.array([3, 8, 4])).all()
```
