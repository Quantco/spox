# Steelix

[![CI](https://github.com/Quantco/steelix/actions/workflows/ci.yml/badge.svg)](https://github.com/Quantco/steelix/actions/workflows/ci.yml)
[![Documentation](https://img.shields.io/badge/docs-latest-success?style=plastic)](https://docs.dev.quantco.cloud/qc-github-artifacts/Quantco/steelix/latest/index.html)

Steelix is a library for constructing ONNX computational graphs.

It's designed to be composable by following functional programming patterns. It abstracts ONNX values to make passing them programmatically easy and predictable, with semantics similar to immutable arrays. The type system is strong and raises during Python construction, rather than ONNX build time, which makes debugging easier.

## Installation

You can install the package in development mode using:

```bash
git clone git@github.com:quantco/steelix.git
cd steelix

# create and activate a fresh environment named steelix
# see environment.yml for details
mamba env create
conda activate steelix

pre-commit install
pip install --no-build-isolation -e .
```

You can install a release of `steelix` with `conda`, once it is published there.

## Introduction

### Arrows

The main abstraction of an ONNX value in Steelix is an `Arrow`. It can be visualised as an edge outgoing from a node.

However, in practice an Arrow may be used similarly to an array with unknown concrete value, but a known shape. For example, given `a: Arrow` and `b: Arrow`, `c: Arrow = add(a, b)` is the Arrow representing the sums of `a` and `b`. `add` is an _operator constructor_, which internally constructs an ONNX Add node and returns an Arrow representing its output.

#### Operator constructors

Operator constructors may be provided with Arrows and constants and return different Arrows. These represent
[ONNX operators](https://github.com/onnx/onnx/blob/main/docs/Operators.md), and they are often similar to numpy functions. Examples include `add`, `matmul`, `reshape`, `unsqueeze`, `loop` etc. Steelix also supports the [ONNX ML operators](https://github.com/onnx/onnx/blob/main/docs/Operators-ml.md).

Constructors are autogenerated with the `src/generate.py` script based on the list of operator schemas provided by `onnx`. The modules with them may be imported from `opset.auto.ai.onnx.*`, at a given version of the opset.

#### Types

Arrows may have different types than arrays (which are called Tensors in ONNX). ONNX also supports sequences and optionals, but they have specialised use cases. An Arrow's type may be accessed with `arrow.type: Type`. Types are defined in the `type_system` module.

### Graphs

To start constructing an ONNX graph, you need to first introduce some Arrows into it. This can be done by calling a function from the `arguments` family. For example, `arguments(**kwargs: Type) -> Tuple[Arrow, ...]` returns argument Arrows with given Types and of names the same as the keys.

To finish constructing an ONNX graph, use a function from the `results` family. For example, `results(**kwargs: Arrow) -> Graph` returns a graph where results are the given Arrows, with the result names as in the keys.

Arguments to a Graph are not explicitly specified, though they may be accessed with the `.arguments` field. They are obtained by traversing the implicit node inputs in the Steelix graph.

Importantly, argument and result names must be pairwise distinct between and within each other. Repeated argument names for distinct Arrows are also an error - if you want to reuse the same argument in different places, explicitly reuse the same Arrow object.

A Steelix `Graph` may be built into ONNX via `.to_onnx(...) -> onnx.GraphProto` or `.to_onnx_model(...) -> onnx.ModelProto`. The set argument/result names are significant, as they become ONNX graph input/output names.

### Running

Once you have constructed an `onnx.ModelProto`, refer to the ONNX documentation on how to process it further. For example, you may save it to a file with `onnx.save` or convert it to bytes via `.SerializeToString()`.

A good next step is to you something like [ONNX Runtime](https://onnxruntime.ai) to execute the computation in the ONNX graph, for example with the Python bindings `onnxruntime`.

### Example usage

This example constructs a graph, taking floating point vectors `a`, `b`, `c`, and returning `r = a*b + c`. As a side note, the preferred floating point type in ONNX is a 32-bit single precision float.

```py
import numpy
import onnxruntime

from steelix import arguments, results, Tensor
import steelix.opset.auto.ai.onnx.v17 as op

# Construct a Tensor type representing a (1D) vector of float32, of size N.
Vectorf32 = Tensor(numpy.float32, ('N',))

# a, b, c are all vectors and named the same in the graph
a, b, c = arguments(a=Vectorf32, b=Vectorf32, c=Vectorf32)

# p represents the Arrow equivalent to a * b
p = op.mul(a, b)
q = op.add(p, c)
# q = op.add(op.mul(a, b), c) works exactly the same

# Construct a Steelix graph with the result
graph = results(r=q)

# We leave Steelix land and use ONNX Runtime to execute
session = onnxruntime.InferenceSession(graph.to_onnx_model().SerializeToString())
(result,) = session.run(None, {
    'a': numpy.array([1, 2, 3], dtype=numpy.float32),
    'b': numpy.array([2, 4, 1], dtype=numpy.float32),
    'c': numpy.array([1, 0, 1], dtype=numpy.float32)
})
# As expected, 3 = 1*2 + 1, etc.
assert (result == numpy.array([3, 8, 4])).all()
```
