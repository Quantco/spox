self.infer_output_types_onnx()
inp, cond = self.inputs.input.unwrap_tensor(), self.inputs.condition.unwrap_tensor()
if not inp.shape:
    return {'output': Tensor(inp.dtype, None)}
if cond.dtype != np.dtype(bool):
    raise InferenceError("Compress input 'condition' must be a boolean dtype.")
if cond.shape and len(cond.shape) != 1:
    raise InferenceError("Compress input 'condition' must be a vector (of rank 1).")
if self.attrs.axis is not None:
    shape = list(inp.shape)
    axis = self.attrs.axis.value
    if not (-len(shape) <= axis < len(shape)):
        raise InferenceError(f"Compress attribute 'axis' must in range [-rank, rank-1] (rank={len(shape)}).")
    shape[axis] = None
else:
    shape = [None]
return {'output': Tensor(inp.dtype, tuple(shape))}